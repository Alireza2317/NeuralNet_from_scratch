{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>...</th>\n",
       "      <th>p775</th>\n",
       "      <th>p776</th>\n",
       "      <th>p777</th>\n",
       "      <th>p778</th>\n",
       "      <th>p779</th>\n",
       "      <th>p780</th>\n",
       "      <th>p781</th>\n",
       "      <th>p782</th>\n",
       "      <th>p783</th>\n",
       "      <th>p784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  p1  p2  p3  p4  p5  p6  p7  p8  p9  ...  p775  p776  p777  p778  \\\n",
       "0      5   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "1      0   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "2      4   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "3      1   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "4      9   0   0   0   0   0   0   0   0   0  ...     0     0     0     0   \n",
       "\n",
       "   p779  p780  p781  p782  p783  p784  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/mnist_mini_train.csv')\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(index):\n",
    "\texample = train_df.iloc[index][1:]\n",
    "\tmatrix = np.array(example).reshape(28, 28)\n",
    "\n",
    "\tplt.imshow(matrix, cmap='gray', vmin=0, vmax=255)\n",
    "\tplt.axis('off')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\tdef __init__(self, *, parameters: np.ndarray) -> None:\n",
    "\t\tif parameters.shape != (13002, 1):\n",
    "\t\t\traise ValueError('parameters shape should be (13002, 1)!')\n",
    "\t\t\n",
    "\t\tself.parameters = parameters\n",
    "\t\t\n",
    "\t\tcount = 0\n",
    "\t\t\n",
    "\t\t# weights1 is of size (16)x(28*28)\n",
    "\t\ttotal_size = 16*28*28\n",
    "\t\tself.weights1 = parameters[count:count+total_size].reshape(16, 28*28)\n",
    "\n",
    "\t\tcount += total_size \n",
    "\n",
    "\t\t# biases1 is of size 16x1\n",
    "\t\ttotal_size = 16*1\n",
    "\t\tself.biases1 = parameters[count:count+total_size].reshape(16, 1)\n",
    "\n",
    "\t\tcount += total_size \n",
    "\n",
    "\t\t# weights2 is of size 16x16\n",
    "\t\ttotal_size = 16*16\n",
    "\t\tself.weights2 = parameters[count:count+total_size].reshape(16, 16)\n",
    "\n",
    "\t\tcount += total_size \n",
    "\n",
    "\t\t# biases2 is of size 16x1\n",
    "\t\ttotal_size = 16*1\n",
    "\t\tself.biases2 = parameters[count:count+total_size].reshape(16, 1)\n",
    "\t\t\n",
    "\t\tcount += total_size \n",
    "\n",
    "\t\t# weights3 is of size 10*16\n",
    "\t\ttotal_size = 10*16\n",
    "\t\tself.weights3 = parameters[count:count+total_size].reshape(10, 16)\n",
    "\n",
    "\t\tcount += total_size \n",
    "\n",
    "\t\t# biases3 is of size 10*1\n",
    "\t\ttotal_size = 10*1\n",
    "\t\tself.biases3 = parameters[count:count+total_size].reshape(10, 1)\n",
    "\n",
    "\t\tself.input_layer = np.zeros((784, 1))\n",
    "\t\t\n",
    "\t\t# inner hidden layers of the network\n",
    "\t\tself.hlayer1 = np.zeros((16, 1))\n",
    "\t\tself.hlayer2 = np.zeros((16, 1))\n",
    "\n",
    "\t\tself.output_layer = np.zeros((10, 1))\n",
    "\n",
    "\t\tdel total_size\n",
    "\t\tdel count\n",
    "\n",
    "\tdef load_input_layer(self, input_vector: np.ndarray) -> None:\n",
    "\t\t\"\"\"\n",
    "\t\t\tLaad the input handwritten digit\n",
    "\t\t\tinput_vector: np.ndarray of shape (784, 1)\n",
    "\t\t\"\"\"\n",
    "\t\tself.input_layer = input_vector\n",
    "\t\t\n",
    "\n",
    "\tdef cost_of_single_sample(self, sample: np.ndarray | pd.DataFrame, true_label: int) -> float:\n",
    "\t\tself.feed_forward()\n",
    "\t\t\n",
    "\t\t# construct the output vector based on the label\n",
    "\t\tdesired_output = np.zeros((10, 1))\n",
    "\t\tdesired_output[true_label] = 1.0\n",
    "\t\t\n",
    "\t\t# compare the self.output_layer and the desired_output\n",
    "\t\t# using mean squared error\n",
    "\t\tMSE = np.sum((self.output_layer - desired_output)**2)\n",
    "\t\treturn MSE\n",
    "\t\n",
    "\tdef desire_of_one_neuron(\n",
    "\t\t\tprevious_layer: np.ndarray,\n",
    "\t\t\tconnection_weights: np.ndarray, \n",
    "\t\t\tconnection_bias: float,\n",
    "\t\t\tdesired_value: float, \n",
    "\t\t\tcurrent_value: float\n",
    "\t\t) -> tuple[np.ndarray, float]:\n",
    "\t\t\"\"\"\n",
    "\t\t\tThis function takes in all the weights and the bias connected to a single neuron\n",
    "\t\t\tand the values of the previous layer, and its current value and the desired value\n",
    "\t\t\tthen it outputs the desired nudges to the weights and the bias\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tchange_strength: float = 1.0\n",
    "\n",
    "\t\tif desired_value > current_value:\n",
    "\t\t\t# neuron's value should increase, so\n",
    "\t\t\t# bias could be increased\n",
    "\t\t\t# weights could be increased in proportion to a_i in previous_layer\n",
    "\t\t\tbias = connection_bias #? how to increase\n",
    "\t\t\tweights = [\n",
    "\t\t\t\tweight + (weight * a * change_strength) #? how to increase\n",
    "\t\t\t\tfor weight, a in zip(connection_weights, previous_layer)\n",
    "\t\t\t]\n",
    "\t\telse:\n",
    "\t\t\t# neuron's value should decrease, so\n",
    "\t\t\t# bias could be decreased\n",
    "\t\t\t# weights could be decreased in proportion to a_i in previous_layer\n",
    "\t\t\tpass\n",
    "\n",
    "\tdef train(self, training_data: np.ndarray | pd.DataFrame):\n",
    "\t\t\"\"\"\n",
    "\t\t\tTrains the model with the labeled training data\n",
    "\t\t\tThe training process:\n",
    "\t\t\t1. initialize self.parameters randomly\n",
    "\t\t\t2. calculate the cost function\n",
    "\t\t\t3. calculate the gradient of the cost function\n",
    "\t\t\t4. adjust the parameters according to the gradient and the learning rate\n",
    "\t\t\t5. repeat until the cost is low enough\n",
    "\t\t\"\"\"\n",
    "\t\tpass\n",
    "\t\n",
    "\t@staticmethod\n",
    "\tdef sigmoid(x: float) -> float:\n",
    "\t\treturn 1 / (1 + np.exp(-x))\n",
    "\n",
    "\tdef feed_forward(self) -> None:\n",
    "\t\t\"\"\"\n",
    "\t\t\tWill calculate all the values in all the layers \n",
    "\t\t\tbased on the weights and biases \n",
    "\t\t\"\"\"\n",
    "\t\t# hidden layer 1 has 16 neurons -> shape: (16, 1)\n",
    "\t\t# weights1.shape = (16, 784)\n",
    "\t\tself.hlayer1 = NeuralNetwork.sigmoid(self.weights1 @ self.input_layer + self.biases1)\n",
    "\t\t# 16*784\t784*1 + 16,1\n",
    "\n",
    "\t\t# hidden layer 2 has 16 neurons -> shape: (16, 1)\n",
    "\t\tself.hlayer2 = NeuralNetwork.sigmoid(self.weights2 @ self.hlayer1 + self.biases2)\n",
    "\t\t\n",
    "\t\t# output layer has 10 neurons -> shape(10, 1)\n",
    "\t\t# one neuron for each digit\n",
    "\t\tself.output_layer = NeuralNetwork.sigmoid(self.weights3 @ self.hlayer2 + self.biases3)\n",
    "\n",
    "\n",
    "\t\tif self.output_layer.shape != (10, 1):\n",
    "\t\t\traise ValueError(f'{self.output_layer.shape}not a correct shape!')\n",
    "\n",
    "\tdef print_network(self, hidden_layers = False) -> None:\n",
    "\t\tif hidden_layers:\n",
    "\t\t\tprint('hLayer 1:')\n",
    "\t\t\tprint(self.hlayer1)\n",
    "\t\t\t\n",
    "\t\t\tprint('hLayer 2:')\n",
    "\t\t\tprint(self.hlayer2)\n",
    "\n",
    "\t\tprint('Output Layer:')\n",
    "\t\tprint(self.output_layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Layer:\n",
      "[[0.99985806]\n",
      " [0.99881395]\n",
      " [0.99989359]\n",
      " [0.99979623]\n",
      " [0.99972895]\n",
      " [0.99914907]\n",
      " [0.99907564]\n",
      " [0.99902346]\n",
      " [0.99994888]\n",
      " [0.99993595]]\n"
     ]
    }
   ],
   "source": [
    "ps = np.random.random((13002, 1))\n",
    "NN = NeuralNetwork(parameters=ps)\n",
    "\n",
    "sample = np.array(train_df.iloc[0][1:]).reshape(784, 1)\n",
    "NN.load_input_layer(input_vector=sample)\n",
    "NN.feed_forward()\n",
    "\n",
    "NN.print_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(8.992823750036704)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.cost_of_single_sample(train_df.iloc[8], 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
